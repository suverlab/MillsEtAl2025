""" 
Constants for use in angleDataframeCreation.py, plottingFunctions.py, importMat.py
    
"""
import numpy as np

#### Directories - PATH to various items, use to set up datastructure
baseDirectory = '/Users/millskm/Desktop/Vanderbilt/SuverLab - Analysis/WindyStepsGeneticAnalysis/' # Main Folder
matDirectory = '/Users/millskm/Desktop/Vanderbilt/SuverLab - Analysis/WindyStepsGeneticAnalysis/mat/' # Folder in which all .mat files are placed
dataDirectory = baseDirectory + 'data/' # Folder which will holder folders for each cameraView with data from DLC
DLCDirectory = baseDirectory + 'DLC/' # Place all DLC projects in this folder

data_path = {} # For each camera view, add path to folder with DLC data
data_path['dorsal'] = dataDirectory + 'data_dorsal/'

config_path = {} # For each camera view, add path to config.yaml file
config_path['dorsal'] = DLCDirectory + 'fancyRig-DLC-2025-01-31/config.yaml'

savedDataFrameDirectory = baseDirectory + 'SavedDataFrames/' # This is where your dataframe for each cameraView will go
savedFigureDirectory = baseDirectory+'Plots/' # Any plots generated by plottingFunctions.py will go here

#### General Information - Code currently only supports one video per trial.

lenVideo = 42 # Length of video in seconds for each trial
fps = 60 # Video Framerate
numFrames = lenVideo * fps # Total number of frames
fs = 20000 # Sampling Rate of DAQ
numSamples = lenVideo * fs

numTrials = 10 # put number of trial per fly here

TRIAL_NUMS_IN_MAT = True
if TRIAL_NUMS_IN_MAT == True:
    trial_num_name = 'trial' # If trial nums are available in mat file, those will be used. If not will iterate from 1 upwards.

#### Experiment-specific information

# IMPORTANT! IF YOUR DAQ ACQUISITION IS LONGER THAN THE VIDEO, SET TRIM = TRUE AND SET TRIM TIMING BELOW. MAKE YOUR TRIM THE
# SAME LENGTH AS THE VIDEO OTHERWISE EVERYTHING WILL BREAK! :) (example: your daq sends a signal for 48 seconds, but you have a 42 second video... make these times match via trim!)
# Trim occurs in importMat.
TRIM = True
if TRIM == True:
    trimStart = 0 # set to start time of excluded daq 
    trimLen = 6 # set to length time of excluded daq

# All values below this point are synced to the video. Any trimmed DAQ is no longer relevant.

# STIMULUS?
STIM = True # Set to True if there is an acitvely controlled stimulus in the experiment
if STIM == True: 
    BASELINE = False # Set to True if there is a baseline period, will take avg over said period and include in dataframe
    if BASELINE == True:
        baselineStart = 0 # set to start time of baseline period
        baselineLen = 6 # set to length time of baseline period

    ONE_STIM = False # Set to true if only one stimulus PERIOD (i.e. tonic opto), will take avg over stim period and include in dataframe
    if ONE_STIM == True:
        stimStart = 4 # set to start time of stimulus period
        stimLen = 6 # set to length time of stimulus period
        MULT_STIM_TYPES = False # Set to True if there are multiple stimulus types in which you want a conditional average for
        if MULT_STIM_TYPES == True:
            stimNames = [] # Set to names of stimuli ### IMPLEMENT CODE ###
            stimNamesInMat = [] # Set to corresponding number/label in .mat file, match with above
    elif ONE_STIM == False:
        stimStart = [0, 6, 12, 18, 24, 30, 36] # set to start time of each stimulus type (example: 0 cm/s wind starts at 0 sec, 50 cm/s starts at 6 sec, etc.)
        stimLen = [6, 6, 6, 6, 6, 6, 6] # set to length time of each stimulus type
        avgStartAndLen = [(3,3),(3,3),(3,3),(3,3),(3,3),(3,3),(3,3)] # set to when average for each stimulus period should run for (i.e starts at 3 seconds, runs for 3 seconds)
        stimNames = ['0','50','100','150','200','250','300']
        MULT_SEQ = True # Set to true if there are multiple stimulus sequence types (i.e ramping up OR ramping down) ##ADVANCED##
        if MULT_SEQ == True:
            seq_order_name = 'stimType' # the name of sequence order in .mat file!
            stimSeqNames = ['Up', 'Down'] # set to names of each sequence type
            stimSeqNumbers = [1, 2] # set to corresponding number/label in .mat file, must match dictionary order and stimSeqNames
            stimSeqs = {
                'Up': ['0','50','100','150','200','250','300'],
                'Down': ['300','250','200','150','100','50','0']
            }

# BEHAVIORAL CATEGORIES?
FLIGHT = True # Only set as True if you wish to distinguish between flight and no flight (i.e. you have a tachometer signal!)
if FLIGHT == True:
    PUFFER = True # Set to True if there is a puffer signal
    if PUFFER == True:
        puffer_signal_name = 'pufferSignal' # set as the name of puffer signal in .mat
        puffer_cutoff_value = 0.9
    flight_cutoff_value = -1.5 # set as cutoff amplitude value for flight vs. no flight
    smoothed_flight_cutoff_value = 0.1 # look at smoothed plot to determine cutoff value for peaks between flight and no flight
    upsideDownHutchens = True # set if hutchens from tachometer extend in the negative direction (means flight would extend below cutoff value)
    raw_signal_name = 'tachometerSignal' # set to name of signal in .mat file
    PRE_FILTERED = True # Set to true if filtering of tachometer signal was done in .mat files
    if PRE_FILTERED == True:
        FILTER_OVERRIDE = True # set to true if you want to use python-based filtering anyways, will replace what is in mat files
        filtered_data_name = 'tachometerSignal_smoothed' #set to name of filtered signal found in .mat file
        
WALKING = False # Not Implemented

#### Angle Setup - Pick which pairs of points best represent each antenna!

bodypartsOfInterestNames = {}
# Place the bodyparts used within deeplabcut here, for each cameraView
bodypartsOfInterestNames['dorsal'] = [
    'L_a_tip', # 0
    'L_a_base', # 1
    'L_f_tip', # 2
    'L_h1_tip', # 3
    'L_h1_base', # 4
    'L_h2_tip', # 5
    'L_h2_base', # 6
    'L_hh_1', # 7
    'L_hh_2', # 8
    'L_hh_3', # 9
    'R_a_tip', # 10
    'R_a_base', # 11
    'R_f_tip', # 12
    'R_h1_tip', # 13
    'R_h1_base', # 14
    'R_h2_tip', # 15
    'R_h2_base', # 16
    'R_hh_1', # 17
    'R_hh_2', # 18
    'R_hh_3', # 19
]

headAxisMarkers = {}
# Place the NUMBER of the points used to mark the head points here for each cameraView...
# Separate into tuples based upon left or right antennae!
# ONLY 2 per tuple, please!
headAxisMarkers['dorsal'] = [(7, 9), (17, 19)]

angPairs = {}
# Pair each NUMBER of a point with its respective other point IPSILATERAL!
# Example: The base of hair one should be paired with its tip
# Do this in tuples, for each cameraView
angPairs['dorsal'] = [(0,1),(3,4), # Left 3rd seg, 2nd seg
                      (10,11),(13,14)] # Right 3rd seg, 2nd seg

ANGPAIR_AVGS = False
if ANGPAIR_AVGS:
    angPairAverageSets = {}
    # Specify, in numpy arrays, the indices w/in angPairs contributing to each antenna.
    # The number of numpy arrays should equal the number of antennae being tracked.
    angPairAverageSets['dorsal'] = [np.array([0,1,2]), #left
                                    np.array([3,4,5])] #right

angPairs_byAntenna = {}
# Specify which tuple(s) in angPairs or angPairsAverageSets belong to each antenna via index. Left should be in first tuple, Right in second tuple.
# TUPLES MUST BE LENGTH 2. First number in each is starting index of pair in angPairs, second number is final index!
# ORGANIZE your ang pairs to be in groups of left and right!
angPairs_byAntenna['dorsal'] = [(0,1),(2,3)] # L, R

upsideDownData = -1 # If you data is upside down, change the sign of this 1.

#### Plotting constants

blue = np.array([0,119,187])/255
teal = np.array([0,153,136])/255
orange = np.array([238,119,51])/255
red = np.array([204,51,17])/255
magenta = np.array([238,51,119])/255

colormap = 'rainbow'
dotsize_bodypart = 4

#blue = np.array([68, 119, 170])/255
#cyan = np.array([68, 119, 170])/255
#green = np.array([68, 119, 170])/255
#yellow = np.array([68, 119, 170])/255
#red = np.array([68, 119, 170])/255
#purple = np.array([68, 119, 170])/255
#grey = np.array([68, 119, 170])/255

HCblue = np.array([0,68,136])/255
HCyellow = np.array([221,170,51])/255
HCred = np.array([187,85,102])/255

vcyan = np.array([51,187,238])/255
vmagneta = np.array([238,51,119])/255

bcyan = np.array([102,204,238])/255
byellow = np.array([204,187,68])/255
bblue = np.array([68,119,170])/255
bred = np.array([238,102,109])/255
bgreen = np.array([34,156,51])/255
bpurp = np.array([170,51,119])/255